# Function Calling åŠŸèƒ½å®ç°æ–‡æ¡£

## ğŸ“‹ æ¦‚è¿°

æœ¬æ–‡æ¡£è®°å½•äº† Yanfeng AI Task é›†æˆä¸­ Function Callingï¼ˆå·¥å…·è°ƒç”¨ï¼‰åŠŸèƒ½çš„å®Œæ•´å®ç°è¿‡ç¨‹ï¼ŒåŒ…æ‹¬é—®é¢˜è¯Šæ–­ã€è§£å†³æ–¹æ¡ˆå’Œæµ‹è¯•éªŒè¯ã€‚

## ğŸ¯ é—®é¢˜æè¿°

### åˆå§‹é—®é¢˜
ç”¨æˆ·å‘ç°åŒæ ·çš„æŸ¥è¯¢è®¾å¤‡ä¿¡æ¯çš„é—®é¢˜ï¼š
- âœ… **Gemini é›†æˆ**ï¼šå¯ä»¥æˆåŠŸè°ƒç”¨ `GetLiveContext` å·¥å…·æŸ¥è¯¢è®¾å¤‡çŠ¶æ€
- âŒ **YanfengAI é›†æˆ**ï¼šæ— æ³•è°ƒç”¨å·¥å…·ï¼Œæ— æ³•æŸ¥è¯¢è®¾å¤‡ä¿¡æ¯

**æµ‹è¯•ç”¨ä¾‹**ï¼š
```
ç”¨æˆ·é—®é¢˜ï¼šç°åœ¨ä¹¦æˆ¿æ¸©åº¦å¤šå°‘ï¼Ÿ
æœŸæœ›è¡Œä¸ºï¼šè°ƒç”¨ GetLiveContext å·¥å…·è·å–è®¾å¤‡çŠ¶æ€ï¼Œè¿”å›æ¸©åº¦ä¿¡æ¯
å®é™…è¡Œä¸ºï¼šæ— æ³•è°ƒç”¨å·¥å…·ï¼Œæ— æ³•è·å–è®¾å¤‡ä¿¡æ¯
```

### æ ¹æœ¬åŸå› åˆ†æ

ç»è¿‡æ·±å…¥è°ƒæŸ¥ï¼Œå‘ç°ä»¥ä¸‹é—®é¢˜ï¼š

1. **ç¼ºå°‘ Function Calling å®ç°**
   - `entity.py` ä¸­æ²¡æœ‰å®ç° OpenAI å…¼å®¹çš„ function calling å¾ªç¯
   - æ²¡æœ‰æå–å’Œæ ¼å¼åŒ– HA æä¾›çš„å·¥å…·ï¼ˆtoolsï¼‰
   - æ²¡æœ‰å¤„ç†æ¨¡å‹è¿”å›çš„å·¥å…·è°ƒç”¨è¯·æ±‚

2. **æ¶ˆæ¯å¤„ç†ä¸å®Œæ•´**
   - æ²¡æœ‰æ­£ç¡®å¤„ç† `ToolResultContent` ç±»å‹çš„æ¶ˆæ¯
   - ç¼ºå°‘å·¥å…·æ‰§è¡Œç»“æœå›ä¼ ç»™æ¨¡å‹çš„é€»è¾‘

3. **API å‚æ•°ç¼ºå¤±**
   - `helpers.py` çš„ `generate_text()` æ–¹æ³•æ²¡æœ‰æ”¯æŒ `tools` å‚æ•°

## ğŸ” è°ƒè¯•è¿‡ç¨‹

### é˜¶æ®µ 1ï¼šéªŒè¯ ModelScope API æ”¯æŒ

**é—®é¢˜**ï¼šéœ€è¦ç¡®è®¤ ModelScope API æ˜¯å¦æ”¯æŒ OpenAI å…¼å®¹çš„ function calling

**æ–¹æ³•**ï¼šåˆ›å»ºæµ‹è¯•è„šæœ¬ `test_function_calling.py`

**æµ‹è¯•ç»“æœ**ï¼š
```
âœ… æµ‹è¯•é€šè¿‡! ModelScope API å®Œå…¨æ”¯æŒ Function Calling!

æµ‹è¯•æµç¨‹ï¼š
1. å‘é€å¸¦å·¥å…·å®šä¹‰çš„è¯·æ±‚
2. æ¨¡å‹è¿”å›å·¥å…·è°ƒç”¨è¯·æ±‚
3. æ‰§è¡Œå·¥å…·ï¼ˆæ¨¡æ‹Ÿï¼‰
4. å‘é€å·¥å…·ç»“æœå›æ¨¡å‹
5. æ¨¡å‹è¿”å›æœ€ç»ˆç­”æ¡ˆ

ç»“è®ºï¼šModelScope API (https://api-inference.modelscope.cn/) å®Œå…¨å…¼å®¹ OpenAI function calling æ ¼å¼
```

### é˜¶æ®µ 2ï¼šå‚è€ƒ Google Generative AI å®ç°

ç ”ç©¶äº† Google Generative AI é›†æˆçš„å®ç°æ¨¡å¼ï¼š
- å·¥å…·æå–å’Œæ ¼å¼åŒ–
- å·¥å…·è°ƒç”¨å¾ªç¯ï¼ˆè¿­ä»£å¤„ç†ï¼‰
- æ¶ˆæ¯å†å²ç®¡ç†
- é”™è¯¯å¤„ç†

### é˜¶æ®µ 3ï¼šå®ç° Function Calling

åŸºäºç ”ç©¶ç»“æœï¼Œå®ç°äº†å®Œæ•´çš„ function calling æ”¯æŒã€‚

## ğŸ› ï¸ ä»£ç æ›´æ”¹

### 1. `helpers.py` - æ·»åŠ å·¥å…·å‚æ•°æ”¯æŒ

**æ–‡ä»¶**ï¼š`custom_components/yanfeng_ai_task/helpers.py`

**æ›´æ”¹**ï¼šåœ¨ `generate_text()` æ–¹æ³•ä¸­æ·»åŠ  `tools` å’Œ `tool_choice` å‚æ•°

```python
async def generate_text(
    self,
    model: str,
    messages: list[dict[str, Any]],
    temperature: float = 0.7,
    top_p: float = 0.9,
    max_tokens: int = 2048,
    stream: bool = False,
    tools: list[dict[str, Any]] | None = None,  # æ–°å¢
    tool_choice: str = "auto",                   # æ–°å¢
) -> dict[str, Any]:
    """Generate text using ModelScope API-Inference with optional function calling."""

    payload = {
        "model": model,
        "messages": messages,
        "temperature": temperature,
        "top_p": top_p,
        "max_tokens": max_tokens,
    }

    # Add tools if provided (OpenAI-compatible function calling)
    if tools:
        payload["tools"] = tools
        payload["tool_choice"] = tool_choice
        LOGGER.debug("Added %d tools to payload with tool_choice=%s", len(tools), tool_choice)

    # ... å…¶ä½™ä»£ç ä¿æŒä¸å˜
```

### 2. `entity.py` - å®ç°å®Œæ•´çš„ Function Calling å¾ªç¯

**æ–‡ä»¶**ï¼š`custom_components/yanfeng_ai_task/entity.py`

#### 2.1 æ·»åŠ å¯¼å…¥å’Œå¸¸é‡

```python
import voluptuous as vol
from voluptuous_openapi import convert
from homeassistant.helpers import llm

# Max number of tool iterations to prevent infinite loops
MAX_TOOL_ITERATIONS = 10
```

#### 2.2 æ·»åŠ å·¥å…·æ ¼å¼åŒ–å‡½æ•°

```python
def _format_tool(tool: llm.Tool, custom_serializer: Any | None) -> dict[str, Any]:
    """Format HA tool to OpenAI/ModelScope compatible format."""
    tool_spec = {
        "type": "function",
        "function": {
            "name": tool.name,
            "description": tool.description or "",
        }
    }

    # Convert parameters schema if provided
    if tool.parameters and tool.parameters.schema:
        try:
            # Use voluptuous_openapi to convert schema
            schema = convert(tool.parameters, custom_serializer=custom_serializer)
            tool_spec["function"]["parameters"] = schema
            LOGGER.debug("Converted tool %s parameters: %s", tool.name, schema)
        except Exception as err:
            LOGGER.warning("Failed to convert parameters for tool %s: %s", tool.name, err)
            # Fallback to empty parameters
            tool_spec["function"]["parameters"] = {
                "type": "object",
                "properties": {},
            }

    return tool_spec
```

#### 2.3 é‡å†™ `_async_handle_chat_log()` æ–¹æ³•

**å…³é”®ç‰¹æ€§**ï¼š
- ä» `chat_log.llm_api` æå–å·¥å…·
- å®ç°å·¥å…·è°ƒç”¨å¾ªç¯ï¼ˆæœ€å¤š 10 æ¬¡è¿­ä»£ï¼‰
- å¤„ç†å·¥å…·è°ƒç”¨è¯·æ±‚å’Œç»“æœ
- æ­£ç¡®æ„é€  `ToolResultContent` å¯¹è±¡
- å¤„ç† VL æ¨¡å‹ä¸æ”¯æŒ function calling çš„æƒ…å†µ

```python
async def _async_handle_chat_log(
    self,
    chat_log: conversation.ChatLog,
    structure: dict[str, Any] | None = None,
) -> None:
    """Handle a chat log by calling the ModelScope API with function calling support."""

    # Get configuration
    model = self._get_option(CONF_CHAT_MODEL, RECOMMENDED_CHAT_MODEL)
    temperature = self._get_option(CONF_TEMPERATURE, DEFAULT_TEMPERATURE)
    top_p = self._get_option(CONF_TOP_P, DEFAULT_TOP_P)
    max_tokens = self._get_option(CONF_MAX_TOKENS, DEFAULT_MAX_TOKENS)
    prompt = self._get_option(CONF_PROMPT, DEFAULT_PROMPT)

    # Extract tools from chat_log if available
    tools = None
    custom_serializer = llm.selector_serializer
    if chat_log.llm_api:
        tools = [
            _format_tool(tool, chat_log.llm_api.custom_serializer)
            for tool in chat_log.llm_api.tools
        ]
        custom_serializer = chat_log.llm_api.custom_serializer
        LOGGER.info("Extracted %d tools from chat_log.llm_api", len(tools))

    # Iterate up to MAX_TOOL_ITERATIONS to handle tool calls
    for iteration in range(MAX_TOOL_ITERATIONS):
        LOGGER.debug("Tool calling iteration %d/%d", iteration + 1, MAX_TOOL_ITERATIONS)

        # Prepare messages from chat_log
        messages = self._prepare_messages_from_chat_log(chat_log, prompt, structure, custom_serializer)

        # Call ModelScope API with tools
        response = await self.client.generate_text(
            model=model,
            messages=messages,
            temperature=temperature,
            top_p=top_p,
            max_tokens=max_tokens,
            tools=tools,
        )

        # Extract response
        choice = response["choices"][0]
        message = choice.get("message", {})

        # Check for tool calls
        tool_calls = message.get("tool_calls")
        content = message.get("content")
        finish_reason = choice.get("finish_reason")

        # Handle edge case: VL models that don't support function calling
        if finish_reason == "tool_calls" and not tool_calls:
            LOGGER.error(
                "Model returned finish_reason='tool_calls' but tool_calls is None. "
                "This usually means the model doesn't fully support function calling. "
                "Consider using Qwen/Qwen2.5-72B-Instruct instead of VL models."
            )
            assistant_content = conversation.AssistantContent(
                agent_id=self.entry.entry_id,
                content="æŠ±æ­‰ï¼Œæˆ‘é‡åˆ°äº†ä¸€ä¸ªé—®é¢˜ã€‚è¯·å°è¯•åˆ‡æ¢åˆ° Qwen/Qwen2.5-72B-Instruct æ¨¡å‹ä»¥è·å¾—æ›´å¥½çš„è®¾å¤‡æ§åˆ¶æ”¯æŒã€‚"
            )
            chat_log.content.append(assistant_content)
            break

        # Add assistant message to chat_log
        if tool_calls:
            # Model wants to call tools
            LOGGER.info("Model requested %d tool calls", len(tool_calls))

            # Convert to HA ToolInput format
            ha_tool_calls = []
            for tool_call in tool_calls:
                function = tool_call.get("function", {})
                tool_name = function.get("name")
                tool_args = function.get("arguments", {})

                # Parse arguments if it's a string
                if isinstance(tool_args, str):
                    import json
                    try:
                        tool_args = json.loads(tool_args)
                    except json.JSONDecodeError as err:
                        LOGGER.error("Failed to parse tool arguments: %s", err)
                        tool_args = {}

                ha_tool_calls.append(
                    llm.ToolInput(tool_name=tool_name, tool_args=tool_args)
                )

            # Add assistant content with tool calls
            assistant_content = conversation.AssistantContent(
                agent_id=self.entry.entry_id,
                content=content or "",  # Content may be empty when calling tools
                tool_calls=ha_tool_calls,
            )
            chat_log.content.append(assistant_content)

            # Execute tools via HA's conversation system
            if chat_log.llm_api:
                for i, tool_call_input in enumerate(ha_tool_calls):
                    try:
                        # Get the tool_call_id from the original response
                        tool_call_id = tool_calls[i].get("id", f"call_{i}")

                        # Execute the tool
                        tool_result = await chat_log.llm_api.async_call_tool(tool_call_input)

                        # Add tool result to chat_log with required parameters
                        tool_result_content = conversation.ToolResultContent(
                            agent_id=self.entry.entry_id,      # å¿…éœ€å‚æ•°
                            tool_call_id=tool_call_id,          # å¿…éœ€å‚æ•°
                            tool_name=tool_call_input.tool_name,
                            tool_result=tool_result,
                        )
                        chat_log.content.append(tool_result_content)

                        LOGGER.debug("Tool %s executed successfully", tool_call_input.tool_name)

                    except Exception as err:
                        LOGGER.error("Error executing tool %s: %s", tool_call_input.tool_name, err)
                        # Add error result with required parameters
                        tool_call_id = tool_calls[i].get("id", f"call_{i}") if i < len(tool_calls) else f"call_{i}"
                        error_result = conversation.ToolResultContent(
                            agent_id=self.entry.entry_id,      # å¿…éœ€å‚æ•°
                            tool_call_id=tool_call_id,          # å¿…éœ€å‚æ•°
                            tool_name=tool_call_input.tool_name,
                            tool_result={"error": str(err)},
                        )
                        chat_log.content.append(error_result)

            # Continue loop to send tool results back to model
            continue

        else:
            # No tool calls, final response
            if content:
                assistant_content = conversation.AssistantContent(
                    agent_id=self.entry.entry_id,
                    content=content
                )
                chat_log.content.append(assistant_content)
                LOGGER.debug("Added final assistant response to chat_log")
            else:
                LOGGER.warning("Empty content in final response")

            # Done, exit loop
            break

    else:
        # Reached MAX_TOOL_ITERATIONS without finishing
        LOGGER.warning("Reached maximum tool iterations (%d), stopping", MAX_TOOL_ITERATIONS)
```

#### 2.4 æ·»åŠ è¾…åŠ©æ–¹æ³•

**`_prepare_messages_from_chat_log()`**ï¼šå‡†å¤‡å‘é€ç»™ API çš„æ¶ˆæ¯åˆ—è¡¨

```python
def _prepare_messages_from_chat_log(
    self,
    chat_log: conversation.ChatLog,
    prompt: str | None,
    structure: dict[str, Any] | None,
    custom_serializer: Any,
) -> list[dict[str, Any]]:
    """Prepare messages list from chat_log content."""
    messages = []

    # Process chat_log content
    for content in chat_log.content:
        if isinstance(content, conversation.SystemContent):
            # Add system content from HA
            messages.append({"role": "system", "content": content.content})
            LOGGER.debug("Added SystemContent: %d chars", len(content.content))

        elif isinstance(content, conversation.UserContent):
            # Add user message
            if content.attachments:
                # Multi-modal content with images
                message_content = []
                if content.content:
                    message_content.append({"type": "text", "text": content.content})

                # Add image attachments
                for attachment in content.attachments:
                    import base64
                    try:
                        with open(attachment.path, 'rb') as img_file:
                            image_data = base64.b64encode(img_file.read()).decode('utf-8')
                            message_content.append({
                                "type": "image_url",
                                "image_url": {
                                    "url": f"data:{attachment.mime_type};base64,{image_data}"
                                }
                            })
                    except Exception as err:
                        LOGGER.error("Failed to read image %s: %s", attachment.path, err)

                messages.append({"role": "user", "content": message_content})
            else:
                # Simple text message
                messages.append({"role": "user", "content": content.content})

        elif isinstance(content, conversation.AssistantContent):
            # Add assistant message
            message = {"role": "assistant"}

            if content.content:
                message["content"] = content.content

            # Add tool calls if present
            if content.tool_calls:
                message["tool_calls"] = [
                    {
                        "id": f"call_{i}",
                        "type": "function",
                        "function": {
                            "name": tc.tool_name,
                            "arguments": tc.tool_args if isinstance(tc.tool_args, str) else str(tc.tool_args),
                        }
                    }
                    for i, tc in enumerate(content.tool_calls)
                ]

            messages.append(message)

        elif isinstance(content, conversation.ToolResultContent):
            # Add tool result as a tool message
            # OpenAI format expects tool messages with tool_call_id
            messages.append({
                "role": "tool",
                "name": content.tool_name,
                "content": str(content.tool_result) if content.tool_result else "{}",
            })
            LOGGER.debug("Added tool result for %s", content.tool_name)

    # Add custom prompt if no system content yet
    has_system_content = any(isinstance(c, conversation.SystemContent) for c in chat_log.content)
    if prompt and not has_system_content:
        messages.insert(0, {"role": "system", "content": prompt})

    # Add structure prompt if needed
    if structure:
        structure_prompt = self._format_structure_prompt(structure, custom_serializer)
        messages.append({"role": "system", "content": structure_prompt})

    return messages
```

### 3. `const.py` - æ·»åŠ æ¨¡å‹é€‰æ‹©è¯´æ˜

**æ–‡ä»¶**ï¼š`custom_components/yanfeng_ai_task/const.py`

**æ›´æ”¹**ï¼šæ·»åŠ å…³äºæ¨¡å‹é€‰æ‹©çš„æ³¨é‡Š

```python
# Recommended models
# Note: Use pure text models for function calling, not VL (Vision-Language) models
RECOMMENDED_CHAT_MODEL = "Qwen/Qwen2.5-72B-Instruct"  # Best for function calling
RECOMMENDED_IMAGE_MODEL = "Qwen/Qwen-Image"
```

**é‡è¦è¯´æ˜**ï¼š
- âœ… **æ¨èä½¿ç”¨çº¯æ–‡æœ¬æ¨¡å‹**ï¼š`Qwen/Qwen2.5-72B-Instruct`ã€`Qwen/Qwen2.5-32B-Instruct` ç­‰
- âŒ **ä¸æ¨è VL æ¨¡å‹ç”¨äºè®¾å¤‡æ§åˆ¶**ï¼š`Qwen/Qwen3-VL-235B-A22B-Instruct` ç­‰è§†è§‰è¯­è¨€æ¨¡å‹å¯¹çº¯æ–‡æœ¬çš„ function calling æ”¯æŒä¸å®Œæ•´

## ğŸ§ª æµ‹è¯•éªŒè¯

### æµ‹è¯•è„šæœ¬

åˆ›å»ºäº† `test_function_calling.py` è„šæœ¬ç”¨äºéªŒè¯ ModelScope API çš„ function calling æ”¯æŒã€‚

**è¿è¡Œæ–¹æ³•**ï¼š
```bash
# æ–¹æ³• 1ï¼šä½¿ç”¨ç¯å¢ƒå˜é‡
export MODELSCOPE_API_KEY='your-api-key'
python test_function_calling.py

# æ–¹æ³• 2ï¼šå‘½ä»¤è¡Œå‚æ•°
python test_function_calling.py your-api-key
```

**æµ‹è¯•å†…å®¹**ï¼š
1. æ™®é€šè°ƒç”¨ï¼ˆä¸å¸¦å·¥å…·ï¼‰
2. å¸¦å·¥å…·è°ƒç”¨ï¼ˆFunction Callingï¼‰
3. å‘é€å·¥å…·æ‰§è¡Œç»“æœå›æ¨¡å‹

**é¢„æœŸç»“æœ**ï¼š
```
âœ… æµ‹è¯•é€šè¿‡! ModelScope API æ”¯æŒ Function Calling!

å·¥å…·è°ƒç”¨æµç¨‹ï¼š
1. ç”¨æˆ·é—®é¢˜ï¼šç°åœ¨ä¹¦æˆ¿çš„æ¸©åº¦æ˜¯å¤šå°‘ï¼Ÿ
2. æ¨¡å‹è¿”å›ï¼štool_call { name: "get_temperature", arguments: {"room": "ä¹¦æˆ¿"} }
3. æ‰§è¡Œå·¥å…·ï¼šè¿”å›æ¸©åº¦æ•°æ® {"temperature": 30.8, "unit": "Â°C"}
4. æ¨¡å‹æœ€ç»ˆå›å¤ï¼šä¹¦æˆ¿çš„æ¸©åº¦ç°åœ¨æ˜¯ 30.8Â°C
```

### é›†æˆæµ‹è¯•

**æµ‹è¯•ç¯å¢ƒ**ï¼šHome Assistant

**æµ‹è¯•æ­¥éª¤**ï¼š

1. **é…ç½®é›†æˆ**
   - è¿›å…¥ **è®¾ç½® > è®¾å¤‡ä¸æœåŠ¡**
   - é…ç½® **Yanfeng AI Task** é›†æˆ
   - é…ç½®å­é¡¹ **Yanfeng AI Conversation**
   - **å…³é”®é…ç½®**ï¼š
     - æ¨¡å‹é€‰æ‹©ï¼š`Qwen/Qwen2.5-72B-Instruct`ï¼ˆä¸è¦ç”¨ VL æ¨¡å‹ï¼‰
     - LLM Hass APIï¼šé€‰æ‹© `Assist`ï¼ˆå¯ç”¨è®¾å¤‡æ§åˆ¶ï¼‰

2. **é‡å¯ Home Assistant**
   ```bash
   # ç¡®ä¿ä»£ç æ›´æ–°ç”Ÿæ•ˆ
   ```

3. **å¯ç”¨è°ƒè¯•æ—¥å¿—**
   åœ¨ `configuration.yaml` ä¸­æ·»åŠ ï¼š
   ```yaml
   logger:
     default: info
     logs:
       custom_components.yanfeng_ai_task: debug
       custom_components.yanfeng_ai_task.entity: debug
       homeassistant.components.conversation: debug
   ```

4. **æµ‹è¯•æŸ¥è¯¢**
   åœ¨ HA çš„å¯¹è¯ç•Œé¢è¾“å…¥ï¼š
   - "ç°åœ¨ä¹¦æˆ¿æ¸©åº¦å¤šå°‘ï¼Ÿ"
   - "å®¢å…ç¯æ˜¯å¼€ç€çš„å—ï¼Ÿ"
   - "ç©ºè°ƒç°åœ¨è®¾ç½®çš„æ˜¯ä»€ä¹ˆæ¸©åº¦ï¼Ÿ"

**é¢„æœŸæ—¥å¿—è¾“å‡º**ï¼š
```
INFO (MainThread) [custom_components.yanfeng_ai_task.entity] Extracted 22 tools from chat_log.llm_api
DEBUG (MainThread) [custom_components.yanfeng_ai_task.entity] Tool calling iteration 1/10
DEBUG (MainThread) [custom_components.yanfeng_ai_task.entity] Sending 3 messages to ModelScope (iteration 1)
INFO (MainThread) [custom_components.yanfeng_ai_task.entity] Model requested 1 tool calls
DEBUG (MainThread) [custom_components.yanfeng_ai_task.entity] Tool GetLiveContext executed successfully
DEBUG (MainThread) [custom_components.yanfeng_ai_task.entity] Tool calling iteration 2/10
DEBUG (MainThread) [custom_components.yanfeng_ai_task.entity] Added final assistant response to chat_log
```

**æˆåŠŸæ ‡å¿—**ï¼š
- âœ… çœ‹åˆ° "Extracted X tools from chat_log.llm_api"
- âœ… çœ‹åˆ° "Model requested X tool calls"
- âœ… çœ‹åˆ° "Tool GetLiveContext executed successfully"
- âœ… æ”¶åˆ°åŒ…å«è®¾å¤‡ä¿¡æ¯çš„å›å¤

## ğŸ› å¸¸è§é—®é¢˜æ’æŸ¥

### é—®é¢˜ 1ï¼šå·¥å…·æ²¡æœ‰è¢«æå–

**ç—‡çŠ¶**ï¼šæ—¥å¿—ä¸­æ²¡æœ‰ "Extracted X tools from chat_log.llm_api"

**åŸå› **ï¼š
- `CONF_LLM_HASS_API` æœªå¯ç”¨
- `chat_log.llm_api` ä¸º None

**è§£å†³æ–¹æ¡ˆ**ï¼š
1. æ£€æŸ¥é…ç½®ï¼šç¡®ä¿åœ¨ Conversation å­é…ç½®ä¸­å¯ç”¨äº† "LLM Hass API"
2. é‡å¯ Home Assistant
3. æŸ¥çœ‹ `conversation.py` çš„æ—¥å¿—ç¡®è®¤é…ç½®æ­£ç¡®

### é—®é¢˜ 2ï¼šæ¨¡å‹ä¸è°ƒç”¨å·¥å…·

**ç—‡çŠ¶**ï¼šæœ‰å·¥å…·å®šä¹‰ï¼Œä½†æ¨¡å‹ç›´æ¥å›ç­”è€Œä¸è°ƒç”¨å·¥å…·

**å¯èƒ½åŸå› **ï¼š
1. ä½¿ç”¨äº† VL æ¨¡å‹ï¼ˆä¸æ”¯æŒçº¯æ–‡æœ¬ function callingï¼‰
2. ç³»ç»Ÿæç¤ºè¯æ²¡æœ‰å¼•å¯¼æ¨¡å‹ä½¿ç”¨å·¥å…·
3. ç”¨æˆ·é—®é¢˜ä¸éœ€è¦å·¥å…·

**è§£å†³æ–¹æ¡ˆ**ï¼š
1. åˆ‡æ¢åˆ°çº¯æ–‡æœ¬æ¨¡å‹ï¼š`Qwen/Qwen2.5-72B-Instruct`
2. æ£€æŸ¥ç³»ç»Ÿæç¤ºè¯æ˜¯å¦æ˜ç¡®æŒ‡ç¤ºä½¿ç”¨å·¥å…·
3. å°è¯•æ›´æ˜ç¡®çš„è®¾å¤‡æŸ¥è¯¢é—®é¢˜

### é—®é¢˜ 3ï¼šToolResultContent å‚æ•°é”™è¯¯

**ç—‡çŠ¶**ï¼š
```
TypeError: ToolResultContent.__init__() missing 2 required positional arguments: 'agent_id' and 'tool_call_id'
```

**åŸå› **ï¼šæ—§ç‰ˆæœ¬ä»£ç æ²¡æœ‰æä¾›å¿…éœ€å‚æ•°

**è§£å†³æ–¹æ¡ˆ**ï¼šç¡®ä¿ä½¿ç”¨æœ€æ–°ç‰ˆæœ¬çš„ `entity.py`ï¼ŒåŒ…å«ä»¥ä¸‹ä¿®å¤ï¼š
```python
tool_result_content = conversation.ToolResultContent(
    agent_id=self.entry.entry_id,      # å¿…éœ€
    tool_call_id=tool_call_id,          # å¿…éœ€
    tool_name=tool_call_input.tool_name,
    tool_result=tool_result,
)
```

### é—®é¢˜ 4ï¼šVL æ¨¡å‹è¿”å› finish_reason='tool_calls' ä½† tool_calls=None

**ç—‡çŠ¶**ï¼š
```
finish_reason: 'tool_calls'
tool_calls: None
```

**åŸå› **ï¼šVLï¼ˆVision-Languageï¼‰æ¨¡å‹å¯¹çº¯æ–‡æœ¬çš„ function calling æ”¯æŒä¸å®Œæ•´

**è§£å†³æ–¹æ¡ˆ**ï¼š
1. åˆ‡æ¢åˆ°çº¯æ–‡æœ¬æ¨¡å‹ï¼š`Qwen/Qwen2.5-72B-Instruct`
2. ä»£ç å·²åŒ…å«æ­¤æƒ…å†µçš„é”™è¯¯å¤„ç†ï¼Œä¼šæç¤ºç”¨æˆ·åˆ‡æ¢æ¨¡å‹

## ğŸ“Š æ€§èƒ½è€ƒè™‘

### å·¥å…·è°ƒç”¨å»¶è¿Ÿ

**å…¸å‹å»¶è¿Ÿ**ï¼š
- ç¬¬ä¸€æ¬¡è°ƒç”¨ï¼ˆå‘é€å·¥å…·è°ƒç”¨è¯·æ±‚ï¼‰ï¼š500-1500ms
- å·¥å…·æ‰§è¡Œï¼š50-200msï¼ˆå–å†³äºå·¥å…·ç±»å‹ï¼‰
- ç¬¬äºŒæ¬¡è°ƒç”¨ï¼ˆå‘é€å·¥å…·ç»“æœï¼Œè·å–æœ€ç»ˆå›å¤ï¼‰ï¼š500-1500ms
- **æ€»è®¡**ï¼šçº¦ 1-3 ç§’

### è¿­ä»£é™åˆ¶

è®¾ç½®äº† `MAX_TOOL_ITERATIONS = 10` é˜²æ­¢æ— é™å¾ªç¯ï¼š
- æ­£å¸¸æƒ…å†µï¼š1-3 æ¬¡è¿­ä»£ï¼ˆåˆå§‹è¯·æ±‚ â†’ å·¥å…·è°ƒç”¨ â†’ æœ€ç»ˆå›å¤ï¼‰
- å¤æ‚ä»»åŠ¡ï¼š3-5 æ¬¡è¿­ä»£ï¼ˆå¤šä¸ªå·¥å…·è°ƒç”¨ï¼‰
- è¾¾åˆ°ä¸Šé™ï¼šè®°å½•è­¦å‘Šæ—¥å¿—å¹¶åœæ­¢

## ğŸ”„ å·¥ä½œæµç¨‹å›¾

```
ç”¨æˆ·é—®é¢˜ï¼š"ä¹¦æˆ¿ç°åœ¨å¤šå°‘åº¦ï¼Ÿ"
    â†“
conversation.py: _async_handle_message()
    â†“
chat_log.async_provide_llm_data() â†’ æä¾›å·¥å…·å®šä¹‰å’Œä¸Šä¸‹æ–‡
    â†“
entity.py: _async_handle_chat_log()
    â†“
æå–å·¥å…· â†’ æ ¼å¼åŒ–ä¸º OpenAI æ ¼å¼
    â†“
ã€ç¬¬1æ¬¡è¿­ä»£ã€‘
    â†“
å‡†å¤‡æ¶ˆæ¯ â†’ è°ƒç”¨ ModelScope APIï¼ˆå¸¦å·¥å…·å®šä¹‰ï¼‰
    â†“
æ¨¡å‹å“åº”: tool_calls = [{"function": {"name": "GetLiveContext", "arguments": {...}}}]
    â†“
æ‰§è¡Œå·¥å…· â†’ chat_log.llm_api.async_call_tool()
    â†“
åˆ›å»º ToolResultContent â†’ æ·»åŠ åˆ° chat_log
    â†“
ã€ç¬¬2æ¬¡è¿­ä»£ã€‘
    â†“
å‡†å¤‡æ¶ˆæ¯ï¼ˆåŒ…å«å·¥å…·ç»“æœï¼‰â†’ è°ƒç”¨ ModelScope API
    â†“
æ¨¡å‹å“åº”: content = "ä¹¦æˆ¿çš„æ¸©åº¦ç°åœ¨æ˜¯ 24.5Â°C"
    â†“
åˆ›å»º AssistantContent â†’ æ·»åŠ åˆ° chat_log
    â†“
è¿”å›æœ€ç»ˆç»“æœç»™ç”¨æˆ·
```

## âœ… éªŒæ”¶æ ‡å‡†

é›†æˆåŠŸèƒ½æ­£å¸¸çš„æ ‡å¿—ï¼š

1. **å·¥å…·æå–æˆåŠŸ**
   - æ—¥å¿—æ˜¾ç¤ºï¼š`Extracted 22 tools from chat_log.llm_api`

2. **æ¨¡å‹è¯·æ±‚å·¥å…·è°ƒç”¨**
   - æ—¥å¿—æ˜¾ç¤ºï¼š`Model requested 1 tool calls`
   - æ—¥å¿—æ˜¾ç¤ºå·¥å…·åç§°å’Œå‚æ•°

3. **å·¥å…·æ‰§è¡ŒæˆåŠŸ**
   - æ—¥å¿—æ˜¾ç¤ºï¼š`Tool GetLiveContext executed successfully`
   - æ²¡æœ‰å¼‚å¸¸æˆ–é”™è¯¯

4. **è·å¾—æœ€ç»ˆå›å¤**
   - æ—¥å¿—æ˜¾ç¤ºï¼š`Added final assistant response to chat_log`
   - ç”¨æˆ·æ”¶åˆ°åŒ…å«è®¾å¤‡ä¿¡æ¯çš„è‡ªç„¶è¯­è¨€å›å¤

5. **ç”¨æˆ·ä½“éªŒ**
   - å›å¤é€Ÿåº¦ï¼š1-3 ç§’ï¼ˆå¯æ¥å—ï¼‰
   - å›å¤å‡†ç¡®ï¼šåŒ…å«æ­£ç¡®çš„è®¾å¤‡çŠ¶æ€ä¿¡æ¯
   - å›å¤è‡ªç„¶ï¼šä½¿ç”¨ä¸­æ–‡è‡ªç„¶è¯­è¨€è¡¨è¾¾

## ğŸ“š å‚è€ƒèµ„æ–™

### Home Assistant æ–‡æ¡£
- [LLM API å¼€å‘æ–‡æ¡£](https://developers.home-assistant.io/docs/core/llm/)
- [Conversation é›†æˆæ–‡æ¡£](https://www.home-assistant.io/integrations/conversation/)

### ModelScope æ–‡æ¡£
- [API æ–‡æ¡£](https://modelscope.cn/docs)
- [Qwen æ¨¡å‹æ–‡æ¡£](https://github.com/QwenLM/Qwen)

### OpenAI Function Calling
- [Function Calling Guide](https://platform.openai.com/docs/guides/function-calling)

### å‚è€ƒå®ç°
- Google Generative AI é›†æˆï¼ˆHome Assistant å®˜æ–¹ï¼‰
- æœ¬é¡¹ç›®çš„ `test_function_calling.py` æµ‹è¯•è„šæœ¬

## ğŸ‰ æ€»ç»“

é€šè¿‡æœ¬æ¬¡å®ç°ï¼š

1. âœ… **å®Œå…¨å®ç°äº† OpenAI å…¼å®¹çš„ Function Calling**
2. âœ… **æ”¯æŒæ‰€æœ‰ Home Assistant æä¾›çš„å·¥å…·**ï¼ˆGetLiveContextã€ControlDevice ç­‰ï¼‰
3. âœ… **æ­£ç¡®å¤„ç†å¤šè½®å·¥å…·è°ƒç”¨**
4. âœ… **æä¾›è¯¦ç»†çš„è°ƒè¯•æ—¥å¿—**
5. âœ… **å¤„ç†é”™è¯¯æƒ…å†µ**ï¼ˆVL æ¨¡å‹ã€å·¥å…·æ‰§è¡Œå¤±è´¥ç­‰ï¼‰

ç°åœ¨ Yanfeng AI Task é›†æˆå¯ä»¥åƒ Gemini ä¸€æ ·æŸ¥è¯¢å’Œæ§åˆ¶ Home Assistant è®¾å¤‡äº†ï¼

---

**æœ€åæ›´æ–°**ï¼š2025-01-17
**ç‰ˆæœ¬**ï¼šv2.0.0
**çŠ¶æ€**ï¼šâœ… å·²å®Œæˆå¹¶æµ‹è¯•
